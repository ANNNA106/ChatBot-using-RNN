{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8844dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ef93dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling, read-binary\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94ed959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd3e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> 1000 10000\n"
     ]
    }
   ],
   "source": [
    "print(type(test_data),type(train_data),len(test_data),len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f5f081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Daniel',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'John',\n",
       "  'picked',\n",
       "  'up',\n",
       "  'the',\n",
       "  'apple',\n",
       "  'there',\n",
       "  '.'],\n",
       " ['Is', 'Daniel', 'in', 'the', 'hallway', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb6840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "Daniel grabbed the apple there.\n",
      "Daniel went to the bedroom.\n",
      "John moved to the garden.\n",
      "Sandra journeyed to the office.\n",
      "Daniel put down the apple.\n",
      "Mary went to the bedroom.\n",
      "Mary grabbed the apple there.\n",
      "Sandra went back to the garden.\n",
      "Mary went to the kitchen.\n",
      "Daniel went to the office.\n",
      "\n",
      "Question: Is Mary in the garden?\n",
      "\n",
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "text=''\n",
    "print('Story:')\n",
    "for sent in train_data[99]:\n",
    "    if sent!='yes' and sent!='no':\n",
    "        for word in sent:\n",
    "            if (word!='.'):\n",
    "                if (word!='?'):\n",
    "                    text+= word + ' '\n",
    "                else:\n",
    "                    print()\n",
    "                    print('Question:', text[:-1]+word)\n",
    "                    print()\n",
    "            else:\n",
    "                print(text[:-1]+word)\n",
    "                text=''\n",
    "    else:\n",
    "        print('Answer:', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a698ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458fbddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749a448e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf106a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8d8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3796c34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87b39da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51cb45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19b94a",
   "metadata": {},
   "source": [
    "Putting the answer Possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc3bb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5628f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d632a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bd1cf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_vocab= len(vocab)+1 #0 for Keras's pad_sequences\n",
    "len_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44f4017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3393fed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])\n",
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a17b9",
   "metadata": {},
   "source": [
    "### VECTORIZING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42232726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4692f059",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56a54c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])   # provide empty list for filter out\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faceb710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journeyed': 1,\n",
       " 'bathroom': 2,\n",
       " 'garden': 3,\n",
       " 'went': 4,\n",
       " 'got': 5,\n",
       " 'up': 6,\n",
       " 'football': 7,\n",
       " 'hallway': 8,\n",
       " 'put': 9,\n",
       " 'in': 10,\n",
       " 'john': 11,\n",
       " 'travelled': 12,\n",
       " 'back': 13,\n",
       " 'milk': 14,\n",
       " 'dropped': 15,\n",
       " 'there': 16,\n",
       " 'apple': 17,\n",
       " 'left': 18,\n",
       " 'the': 19,\n",
       " 'kitchen': 20,\n",
       " 'yes': 21,\n",
       " 'discarded': 22,\n",
       " 'down': 23,\n",
       " 'sandra': 24,\n",
       " '?': 25,\n",
       " 'bedroom': 26,\n",
       " 'took': 27,\n",
       " 'picked': 28,\n",
       " 'mary': 29,\n",
       " 'grabbed': 30,\n",
       " 'daniel': 31,\n",
       " 'office': 32,\n",
       " 'no': 33,\n",
       " 'to': 34,\n",
       " 'is': 35,\n",
       " 'moved': 36,\n",
       " '.': 37}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81ddba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f8b3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f469ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9cf32",
   "metadata": {},
   "source": [
    "# Function for Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58c2a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(vocab_size)  # this includes +1 for padding\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "733c4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "873af91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6acbcec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 19, 26, 37],\n",
       "       [ 0,  0,  0, ..., 19,  3, 37],\n",
       "       [ 0,  0,  0, ..., 19,  3, 37],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 19, 17, 37],\n",
       "       [ 0,  0,  0, ..., 19,  3, 37],\n",
       "       [ 0,  0,  0, ..., 17, 16, 37]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8990ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35, 11, 10, 19, 20, 25],\n",
       "       [35, 11, 10, 19, 20, 25],\n",
       "       [35, 11, 10, 19,  3, 25],\n",
       "       ...,\n",
       "       [35, 29, 10, 19, 26, 25],\n",
       "       [35, 24, 10, 19,  3, 25],\n",
       "       [35, 29, 10, 19,  3, 25]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12178419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "630fc488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       503.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0376b2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13147e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9f7cf",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13f2e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from tensorflow.keras.layers import add, dot, concatenate\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1abc25",
   "metadata": {},
   "source": [
    "There are 2 inputs: stories and questions. We use placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "024f5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3a867",
   "metadata": {},
   "source": [
    "# Network Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96b65d",
   "metadata": {},
   "source": [
    "Input Encoder M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1991c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim= embedding_dim))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d314820",
   "metadata": {},
   "source": [
    "Input Encoder C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a6e77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f76c7",
   "metadata": {},
   "source": [
    "Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b581c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embedding_dim,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55b12f",
   "metadata": {},
   "source": [
    "Encode the Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77531784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices) to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f91d7",
   "metadata": {},
   "source": [
    "Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fa8325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1c78e",
   "metadata": {},
   "source": [
    "Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91843cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb191d",
   "metadata": {},
   "source": [
    "Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b24f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "# (samples, query_maxlen, story_maxlen + embedding_dim)\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e171a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 284) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "977e5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # shape (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3a34e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf1362c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad535f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 156)]                0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 6)]                  0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, None, 128)            4864      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)   (None, 6, 128)               4864      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 156, 6)               0         ['sequential[0][0]',          \n",
      "                                                                     'sequential_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 156, 6)               0         ['dot[0][0]']                 \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, None, 6)              228       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 156, 6)               0         ['activation[0][0]',          \n",
      "                                                                     'sequential_1[0][0]']        \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 6, 156)               0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 6, 284)               0         ['permute[0][0]',             \n",
      "                                                                     'sequential_2[0][0]']        \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 32)                   40576     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 32)                   0         ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 38)                   1254      ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 38)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51786 (202.29 KB)\n",
      "Trainable params: 51786 (202.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bceab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "epochs = 120\n",
    "decay = initial_learning_rate / epochs\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 20\n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.66, patience=5, min_lr=0.0001, verbose=1)  # factor by which the learning rate will be reduced. new_lr = lr * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ac95677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "40/40 [==============================] - 3s 42ms/step - loss: 0.9041 - accuracy: 0.4869 - val_loss: 0.7415 - val_accuracy: 0.4970\n",
      "Epoch 2/120\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.7099 - accuracy: 0.4955 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.7027 - accuracy: 0.4951 - val_loss: 0.7512 - val_accuracy: 0.4970\n",
      "Epoch 4/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.7015 - accuracy: 0.5089 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.7011 - accuracy: 0.5051 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.7029 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.7013 - accuracy: 0.4978 - val_loss: 0.7165 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.7010 - accuracy: 0.5064 - val_loss: 0.7978 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.7029 - accuracy: 0.4981 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 10/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.7008 - accuracy: 0.4929 - val_loss: 0.7390 - val_accuracy: 0.5030\n",
      "Epoch 11/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.7001 - accuracy: 0.5003 - val_loss: 0.7592 - val_accuracy: 0.5030\n",
      "Epoch 12/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.7008 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 13/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.7010 - accuracy: 0.4924 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 14/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6984 - accuracy: 0.5055 - val_loss: 0.7735 - val_accuracy: 0.4970\n",
      "Epoch 15/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.7000 - accuracy: 0.5000 - val_loss: 0.7476 - val_accuracy: 0.4970\n",
      "Epoch 16/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6999 - accuracy: 0.4994 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 17/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6979 - accuracy: 0.5036 - val_loss: 0.7337 - val_accuracy: 0.5030\n",
      "Epoch 18/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.7001 - accuracy: 0.4972 - val_loss: 0.7222 - val_accuracy: 0.4970\n",
      "Epoch 19/120\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6978 - accuracy: 0.5068 - val_loss: 0.7169 - val_accuracy: 0.4970\n",
      "Epoch 20/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.6999 - accuracy: 0.4964 - val_loss: 0.6969 - val_accuracy: 0.5030\n",
      "Epoch 21/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6974 - accuracy: 0.4986 - val_loss: 0.7028 - val_accuracy: 0.4970\n",
      "Epoch 22/120\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6996 - accuracy: 0.4878 - val_loss: 0.7035 - val_accuracy: 0.5030\n",
      "Epoch 23/120\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.6993 - accuracy: 0.4947 - val_loss: 0.7583 - val_accuracy: 0.4970\n",
      "Epoch 24/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6984 - accuracy: 0.4959 - val_loss: 0.7042 - val_accuracy: 0.4970\n",
      "Epoch 25/120\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.6981 - accuracy: 0.5029 - val_loss: 0.7356 - val_accuracy: 0.5030\n",
      "Epoch 26/120\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6986 - accuracy: 0.5039 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 27/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6975 - accuracy: 0.4966 - val_loss: 0.6989 - val_accuracy: 0.4970\n",
      "Epoch 28/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6980 - accuracy: 0.4974 - val_loss: 0.7111 - val_accuracy: 0.4970\n",
      "Epoch 29/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6983 - accuracy: 0.4996 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
      "Epoch 30/120\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6975 - accuracy: 0.4897 - val_loss: 0.7080 - val_accuracy: 0.4970\n",
      "Epoch 31/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6971 - accuracy: 0.4981 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 32/120\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6970 - accuracy: 0.5025 - val_loss: 0.6955 - val_accuracy: 0.5030\n",
      "Epoch 33/120\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6979 - accuracy: 0.4983 - val_loss: 0.7060 - val_accuracy: 0.4970\n",
      "Epoch 34/120\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.6966 - accuracy: 0.5057 - val_loss: 0.7541 - val_accuracy: 0.5030\n",
      "Epoch 35/120\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.7002 - accuracy: 0.4942 - val_loss: 0.6944 - val_accuracy: 0.5030\n",
      "Epoch 36/120\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6964 - accuracy: 0.5032 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
      "Epoch 37/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6968 - accuracy: 0.4952 - val_loss: 0.7487 - val_accuracy: 0.4970\n",
      "Epoch 38/120\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6985 - accuracy: 0.5037 - val_loss: 0.6976 - val_accuracy: 0.5030\n",
      "Epoch 39/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6958 - accuracy: 0.5067 - val_loss: 0.7182 - val_accuracy: 0.5030\n",
      "Epoch 40/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6969 - accuracy: 0.5037 - val_loss: 0.6977 - val_accuracy: 0.4970\n",
      "Epoch 41/120\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6970 - accuracy: 0.4983 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 42/120\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6963 - accuracy: 0.4994 - val_loss: 0.6981 - val_accuracy: 0.4970\n",
      "Epoch 43/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6964 - accuracy: 0.5058 - val_loss: 0.6952 - val_accuracy: 0.5040\n",
      "Epoch 44/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6962 - accuracy: 0.5151 - val_loss: 0.7161 - val_accuracy: 0.5030\n",
      "Epoch 45/120\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.6958 - accuracy: 0.5153 - val_loss: 0.7193 - val_accuracy: 0.4970\n",
      "Epoch 46/120\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.6964 - accuracy: 0.5088 - val_loss: 0.7108 - val_accuracy: 0.4970\n",
      "Epoch 47/120\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.6951 - accuracy: 0.5147 - val_loss: 0.7100 - val_accuracy: 0.5050\n",
      "Epoch 48/120\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.6923 - accuracy: 0.5329 - val_loss: 0.6934 - val_accuracy: 0.5060\n",
      "Epoch 49/120\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6861 - accuracy: 0.5427 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 50/120\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.6701 - accuracy: 0.5796 - val_loss: 0.6472 - val_accuracy: 0.6280\n",
      "Epoch 51/120\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6519 - accuracy: 0.6050 - val_loss: 0.6236 - val_accuracy: 0.6460\n",
      "Epoch 52/120\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.6361 - accuracy: 0.6358 - val_loss: 0.6164 - val_accuracy: 0.6550\n",
      "Epoch 53/120\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6182 - accuracy: 0.6606 - val_loss: 0.6080 - val_accuracy: 0.7110\n",
      "Epoch 54/120\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.5915 - accuracy: 0.6869 - val_loss: 0.5938 - val_accuracy: 0.6650\n",
      "Epoch 55/120\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.5702 - accuracy: 0.7090 - val_loss: 0.5487 - val_accuracy: 0.7140\n",
      "Epoch 56/120\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.5454 - accuracy: 0.7266 - val_loss: 0.6153 - val_accuracy: 0.6470\n",
      "Epoch 57/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5148 - accuracy: 0.7525 - val_loss: 0.5840 - val_accuracy: 0.6920\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 37ms/step - loss: 0.4959 - accuracy: 0.7695 - val_loss: 0.4924 - val_accuracy: 0.7580\n",
      "Epoch 59/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.4669 - accuracy: 0.7891 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 60/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.4455 - accuracy: 0.7940 - val_loss: 0.5040 - val_accuracy: 0.7580\n",
      "Epoch 61/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.4332 - accuracy: 0.8020 - val_loss: 0.4689 - val_accuracy: 0.7850\n",
      "Epoch 62/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.4183 - accuracy: 0.8106 - val_loss: 0.4976 - val_accuracy: 0.7690\n",
      "Epoch 63/120\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.4123 - accuracy: 0.8104 - val_loss: 0.4309 - val_accuracy: 0.8140\n",
      "Epoch 64/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.4020 - accuracy: 0.8206 - val_loss: 0.4363 - val_accuracy: 0.8030\n",
      "Epoch 65/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.3973 - accuracy: 0.8240 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 66/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3896 - accuracy: 0.8209 - val_loss: 0.5044 - val_accuracy: 0.7790\n",
      "Epoch 67/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.3884 - accuracy: 0.8225 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 68/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.3873 - accuracy: 0.8245 - val_loss: 0.4507 - val_accuracy: 0.7790\n",
      "Epoch 69/120\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.3773 - accuracy: 0.8292 - val_loss: 0.4876 - val_accuracy: 0.8000\n",
      "Epoch 70/120\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.3689 - accuracy: 0.8366 - val_loss: 0.4171 - val_accuracy: 0.8140\n",
      "Epoch 71/120\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.3731 - accuracy: 0.8323 - val_loss: 0.4335 - val_accuracy: 0.8100\n",
      "Epoch 72/120\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.3685 - accuracy: 0.8318 - val_loss: 0.4348 - val_accuracy: 0.7950\n",
      "Epoch 73/120\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.3612 - accuracy: 0.8381 - val_loss: 0.4225 - val_accuracy: 0.8030\n",
      "Epoch 74/120\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.3594 - accuracy: 0.8359 - val_loss: 0.4499 - val_accuracy: 0.7820\n",
      "Epoch 75/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3570 - accuracy: 0.8350 - val_loss: 0.4465 - val_accuracy: 0.8120\n",
      "Epoch 76/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.3458 - accuracy: 0.8452 - val_loss: 0.4504 - val_accuracy: 0.8200\n",
      "Epoch 77/120\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3471 - accuracy: 0.8450 - val_loss: 0.4083 - val_accuracy: 0.8090\n",
      "Epoch 78/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3421 - accuracy: 0.8525 - val_loss: 0.4564 - val_accuracy: 0.8010\n",
      "Epoch 79/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3398 - accuracy: 0.8516 - val_loss: 0.4173 - val_accuracy: 0.8010\n",
      "Epoch 80/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3339 - accuracy: 0.8542 - val_loss: 0.4340 - val_accuracy: 0.7960\n",
      "Epoch 81/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.3320 - accuracy: 0.8527 - val_loss: 0.3749 - val_accuracy: 0.8200\n",
      "Epoch 82/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3335 - accuracy: 0.8558 - val_loss: 0.4844 - val_accuracy: 0.7960\n",
      "Epoch 83/120\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3283 - accuracy: 0.8571 - val_loss: 0.4559 - val_accuracy: 0.8020\n",
      "Epoch 84/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.3142 - accuracy: 0.8641 - val_loss: 0.4680 - val_accuracy: 0.8100\n",
      "Epoch 85/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3212 - accuracy: 0.8558 - val_loss: 0.4023 - val_accuracy: 0.8170\n",
      "Epoch 86/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3161 - accuracy: 0.8624 - val_loss: 0.4821 - val_accuracy: 0.8010\n",
      "Epoch 87/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3173 - accuracy: 0.8584 - val_loss: 0.4132 - val_accuracy: 0.8040\n",
      "Epoch 88/120\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.3063 - accuracy: 0.8666 - val_loss: 0.5275 - val_accuracy: 0.7830\n",
      "Epoch 89/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3104 - accuracy: 0.8654 - val_loss: 0.4048 - val_accuracy: 0.8130\n",
      "Epoch 90/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.3094 - accuracy: 0.8637 - val_loss: 0.4373 - val_accuracy: 0.8010\n",
      "Epoch 91/120\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.3006 - accuracy: 0.8686 - val_loss: 0.4355 - val_accuracy: 0.8140\n",
      "Epoch 92/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.3044 - accuracy: 0.8669 - val_loss: 0.4424 - val_accuracy: 0.8160\n",
      "Epoch 93/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2953 - accuracy: 0.8697 - val_loss: 0.4301 - val_accuracy: 0.8080\n",
      "Epoch 94/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2972 - accuracy: 0.8687 - val_loss: 0.4557 - val_accuracy: 0.7820\n",
      "Epoch 95/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2949 - accuracy: 0.8716 - val_loss: 0.4678 - val_accuracy: 0.8240\n",
      "Epoch 96/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.2979 - accuracy: 0.8664 - val_loss: 0.4044 - val_accuracy: 0.8150\n",
      "Epoch 97/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2937 - accuracy: 0.8715 - val_loss: 0.4950 - val_accuracy: 0.7900\n",
      "Epoch 98/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2987 - accuracy: 0.8716 - val_loss: 0.5259 - val_accuracy: 0.8090\n",
      "Epoch 99/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2916 - accuracy: 0.8705 - val_loss: 0.4166 - val_accuracy: 0.8130\n",
      "Epoch 100/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2925 - accuracy: 0.8733 - val_loss: 0.4582 - val_accuracy: 0.8120\n",
      "Epoch 101/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2847 - accuracy: 0.8762 - val_loss: 0.4181 - val_accuracy: 0.8180\n",
      "Epoch 102/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2782 - accuracy: 0.8785 - val_loss: 0.4173 - val_accuracy: 0.8190\n",
      "Epoch 103/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2791 - accuracy: 0.8773 - val_loss: 0.4797 - val_accuracy: 0.7950\n",
      "Epoch 104/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2793 - accuracy: 0.8764 - val_loss: 0.4284 - val_accuracy: 0.8170\n",
      "Epoch 105/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2874 - accuracy: 0.8754 - val_loss: 0.4071 - val_accuracy: 0.8150\n",
      "Epoch 106/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2662 - accuracy: 0.8836 - val_loss: 0.4655 - val_accuracy: 0.8160\n",
      "Epoch 107/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2743 - accuracy: 0.8786 - val_loss: 0.4612 - val_accuracy: 0.8220\n",
      "Epoch 108/120\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.2729 - accuracy: 0.8804 - val_loss: 0.5062 - val_accuracy: 0.8160\n",
      "Epoch 109/120\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.2784 - accuracy: 0.8779 - val_loss: 0.5579 - val_accuracy: 0.7960\n",
      "Epoch 110/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2756 - accuracy: 0.8802 - val_loss: 0.4287 - val_accuracy: 0.8010\n",
      "Epoch 111/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2664 - accuracy: 0.8865 - val_loss: 0.4333 - val_accuracy: 0.8330\n",
      "Epoch 112/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2681 - accuracy: 0.8817 - val_loss: 0.4486 - val_accuracy: 0.8270\n",
      "Epoch 113/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2571 - accuracy: 0.8894 - val_loss: 0.4552 - val_accuracy: 0.8130\n",
      "Epoch 114/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2649 - accuracy: 0.8833 - val_loss: 0.4901 - val_accuracy: 0.7950\n",
      "Epoch 115/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 36ms/step - loss: 0.2650 - accuracy: 0.8834 - val_loss: 0.4993 - val_accuracy: 0.8090\n",
      "Epoch 116/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.2620 - accuracy: 0.8817 - val_loss: 0.4381 - val_accuracy: 0.8190\n",
      "Epoch 117/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.2592 - accuracy: 0.8854 - val_loss: 0.5194 - val_accuracy: 0.8130\n",
      "Epoch 118/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.2578 - accuracy: 0.8891 - val_loss: 0.4678 - val_accuracy: 0.8190\n",
      "Epoch 119/120\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.2541 - accuracy: 0.8911 - val_loss: 0.4958 - val_accuracy: 0.8200\n",
      "Epoch 120/120\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2574 - accuracy: 0.8889 - val_loss: 0.5523 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=256,epochs=120,validation_data=([inputs_test, queries_test], answers_test))  # , callbacks=[reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b3be20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchatbot_120_epochs_9710.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39msave(filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('accuracy.png', dpi=180, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b59a490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a59fff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32405d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "879af3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e98e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"Real answer:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9580685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999926\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer:\", k)\n",
    "print(\"Accuracy: \", 100*pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33adfb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
